{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lyq\\.conda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from MLPN.loader import init_dataset_train, label2tensor, tensor2label\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lyq\\.conda\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn import functional as F\n",
    "from utils.common import setup_seed \n",
    "from MLPN.loader import init_dataset_train\n",
    "from utils.loader import  init_dataset_test, environments\n",
    "from utils.metrics import metrics\n",
    "from MLPN.model import CSWinTransv2_threeIn\n",
    "from MLPN.utils import extract_feature, get_id, extract_feature, SAM, SupConLoss, one_LPN_output\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm.contrib import tzip\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "from LPN.image_folder_ import CustomData160k_drone, CustomData160k_sat\n",
    "from utils.competition import get_result_rank10, get_SatId_160k\n",
    "\n",
    "\n",
    "###########################\n",
    "\n",
    "import os\n",
    "import math\n",
    "from shutil import copyfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from utils.common import setup_seed \n",
    "from utils.loader import environments, init_dataset_train, tensor2label, label2tensor, init_dataset_test\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "\n",
    "class DomainClassifier(nn.Module):\n",
    "    def __init__(self, domin_num=10) -> None:\n",
    "        super(DomainClassifier, self).__init__()\n",
    "        \n",
    "        # adatped from modern backbone, change last fc to adopt domain\n",
    "        self.net = models.resnet18(pretrained=True)\n",
    "        ftr_num = self.net.fc.in_features\n",
    "        self.net.fc = nn.Linear(ftr_num, domin_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class MLPN_ensemble(nn.Module):\n",
    "    def __init__(self,\n",
    "                 replace = ['snow', 'fog', 'fog_rain', 'fog_snow', 'rain_snow'],\n",
    "                 block = 4\n",
    "                 ):\n",
    "        super(MLPN_ensemble, self).__init__()\n",
    "        self.model_dir = os.path.join(os.getcwd(), 'model', 'MLPNs')\n",
    "\n",
    "        self.domain_classifier = DomainClassifier()\n",
    "        self.domain_classifier.load_state_dict(torch.load(os.path.join(self.model_dir, 'DomainClassifier_060.pth')))\n",
    "        self.domain_classifier.cuda()\n",
    "        self.domain_classifier.train(False)\n",
    "\n",
    "        self.ft = {i: CSWinTransv2_threeIn(701, droprate=0.75, decouple=False, infonce=1) for i in environments}\n",
    "        model_path_default = os.path.join(self.model_dir, 'net_170.pth')\n",
    "        for style in environments:\n",
    "            model_path = os.path.join(self.model_dir, '{}_120.pth'.format(style))\n",
    "            if os.path.isfile(model_path) and style in replace:\n",
    "                self.ft[style].load_state_dict(torch.load(model_path))\n",
    "            else:\n",
    "                self.ft[style].load_state_dict(torch.load(model_path_default))\n",
    "            \n",
    "            for i in range(block):\n",
    "                cls_name = 'classifier'+str(i)\n",
    "                c = getattr(self.ft[style], cls_name)\n",
    "                c.classifier = nn.Sequential()\n",
    "\n",
    "            self.ft[style].cuda()   \n",
    "            self.ft[style].train(False) \n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.domain_classifier(x) \n",
    "        pred = tensor2label(logits)\n",
    "        # print(pred)\n",
    "        xx = list()\n",
    "        for i in range(len(pred)):\n",
    "            feature = self.ft[pred[i]](x[i].unsqueeze(0))\n",
    "            xx.append(feature[0])\n",
    "        xxx = torch.cat(xx, 0)\n",
    "        # print(xxx.shape)\n",
    "        return [xxx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MLPN_ensemble_:\n",
    "    def __init__(self, \n",
    "                 use_wandb=True,\n",
    "                 wandb_key = '16c9a3f92163ef4df08841029e02fded0cd0cfed') -> None:\n",
    "        # default parameters\n",
    "        self.seed = 2024\n",
    "        self.use_wandb = use_wandb # use wandb to monitor training instead of CLI\n",
    "        self.wandb_key = wandb_key\n",
    "\n",
    "        self.pytorch_version =  torch.__version__      \n",
    "        self.w = 256\n",
    "        self.h = 256\n",
    "\n",
    "        # init\n",
    "        setup_seed(self.seed)\n",
    "        self.model_dir = os.path.join(os.getcwd(), 'model', 'MLPN')\n",
    "        os.environ['TORCH_HOME']='./'   \n",
    "\n",
    "\n",
    "    def test(self, pth=None, query='drone', gallery='satellite', multiple_scale=[1], batchsize=128, style='mixed'):\n",
    "        # load data\n",
    "        image_datasets, dataloaders, dataset_sizes = init_dataset_test(batchsize=batchsize, style=style, w=self.w, h=self.h)\n",
    "        # init label\n",
    "        gallery_name = 'gallery_' + gallery\n",
    "        query_name = 'query_' + query \n",
    "        gallery_label = get_id(image_datasets[gallery_name].imgs)\n",
    "        query_label = get_id(image_datasets[query_name].imgs)\n",
    "        # print(dataset_sizes[gallery_name])\n",
    "        # load model\n",
    "        \n",
    "        model = self.load_model(pth=pth)\n",
    "        # extract features\n",
    "        with torch.no_grad():\n",
    "            query_feature = extract_feature(model,dataloaders[query_name], view=query, ms=multiple_scale)\n",
    "            gallery_feature = extract_feature(model,dataloaders[gallery_name], view=gallery, ms=multiple_scale)\n",
    "\n",
    "        # calculate \n",
    "        m = metrics(query_feature, query_label, gallery_feature, gallery_label)\n",
    "        print(\"Recall@1: {:.2f}\".format(m[0]))\n",
    "        print(\"Recall@5: {:.2f}\".format(m[1]))\n",
    "        print(\"Recall@10: {:.2f}\".format(m[2]))\n",
    "        print(\"Recall@top1: {:.2f}\".format(m[3]))\n",
    "        print(\"Recall@AP: {:.2f}\".format(m[4]))\n",
    "        # return m\n",
    "\n",
    "    def get_competition_submit(self, data160k_dir='D://dataset/university-160k-wx', save_file = 'answer.txt', pth=None, multiple_scale=[1], batchsize=128):\n",
    "        # a part of test set of UAVM'24 competition is provided as tar file\n",
    "        if not os.path.exists(os.path.join(data160k_dir, 'gallery_satellite_160k')):\n",
    "            tar_file = os.path.join(data160k_dir, 'gallery_satellite_160k.tar.gz')\n",
    "            if os.path.isfile(tar_file):\n",
    "                print('Found dataset tar file. Extracting...')\n",
    "                with tarfile.open(tar_file, 'r:gz') as tar:\n",
    "                    tar.extractall(path=data160k_dir)\n",
    "                print('Extract done')\n",
    "        else:\n",
    "            print('Found dataset')\n",
    "\n",
    "        query_name = os.path.join(data160k_dir, 'query_drone_name.txt')\n",
    "        if os.path.isfile(save_file):\n",
    "            os.remove(save_file) \n",
    "            os.remove('answer.zip')\n",
    "        results_rank10 = [] \n",
    "\n",
    "        data_transforms = transforms.Compose([\n",
    "            transforms.Resize((self.h, self.w), interpolation=InterpolationMode.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "        image_datasets = {}\n",
    "        image_datasets['gallery_satellite_160k'] = CustomData160k_sat(os.path.join(data160k_dir, 'gallery_satellite_160k'), data_transforms)\n",
    "        image_datasets['query_drone_160k'] = CustomData160k_drone( os.path.join(data160k_dir, 'query_drone160k_wx') ,data_transforms, query_name = query_name)\n",
    "\n",
    "        dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batchsize,\n",
    "                                                        shuffle=False, num_workers=16) for x in\n",
    "                        ['gallery_satellite_160k','query_drone_160k']}\n",
    "        \n",
    "        gallery_path = image_datasets['gallery_satellite_160k'].imgs\n",
    "        gallery_label, gallery_path  = get_SatId_160k(gallery_path)\n",
    "        \n",
    "        # load model\n",
    "        # model = self.load_model(pth=pth)\n",
    "        model = MLPN_ensemble()\n",
    "\n",
    "        # Extract features\n",
    "        with torch.no_grad():\n",
    "            query_feature = extract_feature(model,dataloaders['query_drone_160k'], view='drone', ms=multiple_scale, testing=True)\n",
    "            gallery_feature = extract_feature(model,dataloaders['gallery_satellite_160k'], view='satellite', ms=multiple_scale)\n",
    "        \n",
    "        query_feature = query_feature.cuda()\n",
    "        gallery_feature = gallery_feature.cuda()\n",
    "\n",
    "        gallery_label = np.array(gallery_label)\n",
    "        for i in tqdm(range(len(query_feature)), desc='Evaluate Rank10 results'):\n",
    "            result_rank10 = get_result_rank10(query_feature[i], gallery_feature, gallery_label)\n",
    "            results_rank10.append(result_rank10)\n",
    "            \n",
    "        results_rank10 = np.row_stack(results_rank10)\n",
    "        with open(save_file, 'w') as f:\n",
    "            for row in results_rank10:\n",
    "                f.write('\\t'.join(map(str, row)) + '\\n')\n",
    "\n",
    "        # zip\n",
    "        zip_name = os.path.join(os.getcwd(), 'answer.zip')\n",
    "        with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "            zipf.write(save_file, save_file)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MLPN_ensemble_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lyq\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lyq\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\lyq\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:2895.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "Extract drone feature: 100%|██████████| 296/296 [33:18<00:00,  6.75s/it]\n",
      "Extract satellite feature: 100%|██████████| 1316/1316 [2:31:05<00:00,  6.89s/it] \n",
      "Evaluate Rank10 results: 100%|██████████| 37855/37855 [10:05<00:00, 62.51it/s]\n"
     ]
    }
   ],
   "source": [
    "m.get_competition_submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "951\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [49:35<00:00, 10.05s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:44<00:00,  5.59s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:12<00:00, 3013.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 91.75\n",
      "Recall@5: 97.59\n",
      "Recall@10: 98.44\n",
      "Recall@top1: 98.54\n",
      "Recall@AP: 93.05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(91.7475),\n",
       " tensor(97.5882),\n",
       " tensor(98.4361),\n",
       " tensor(98.5418),\n",
       " 93.05280791725373)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MLPN_()\n",
    "m.batchsize=128\n",
    "m.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [21:00<00:00,  4.26s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:44<00:00,  5.55s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:13<00:00, 2883.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 94.07\n",
      "Recall@5: 98.34\n",
      "Recall@10: 98.79\n",
      "Recall@top1: 98.86\n",
      "Recall@AP: 95.03\n",
      "dark\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [21:45<00:00,  4.41s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:44<00:00,  5.50s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:12<00:00, 2924.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 93.92\n",
      "Recall@5: 98.32\n",
      "Recall@10: 98.85\n",
      "Recall@top1: 98.90\n",
      "Recall@AP: 94.91\n",
      "fog\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [27:21<00:00,  5.55s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:44<00:00,  5.54s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:12<00:00, 2916.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 93.38\n",
      "Recall@5: 98.10\n",
      "Recall@10: 98.71\n",
      "Recall@top1: 98.79\n",
      "Recall@AP: 94.45\n",
      "rain\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:40:01<00:00, 20.27s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:49<00:00,  6.15s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:14<00:00, 2653.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 92.05\n",
      "Recall@5: 97.69\n",
      "Recall@10: 98.52\n",
      "Recall@top1: 98.63\n",
      "Recall@AP: 93.31\n",
      "snow\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:04:50<00:00, 13.15s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:48<00:00,  6.11s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:13<00:00, 2875.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 90.97\n",
      "Recall@5: 97.39\n",
      "Recall@10: 98.27\n",
      "Recall@top1: 98.40\n",
      "Recall@AP: 92.41\n",
      "fog_rain\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:01:38<00:00, 12.50s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.43s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:13<00:00, 2890.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 91.27\n",
      "Recall@5: 97.38\n",
      "Recall@10: 98.37\n",
      "Recall@top1: 98.44\n",
      "Recall@AP: 92.64\n",
      "fog_snow\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [43:37<00:00,  8.84s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:51<00:00,  6.42s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:16<00:00, 2254.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 89.94\n",
      "Recall@5: 96.94\n",
      "Recall@10: 98.05\n",
      "Recall@top1: 98.17\n",
      "Recall@AP: 91.52\n",
      "rain_snow\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:33:36<00:00, 18.98s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:41<00:00,  5.20s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:13<00:00, 2752.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 91.23\n",
      "Recall@5: 97.36\n",
      "Recall@10: 98.33\n",
      "Recall@top1: 98.40\n",
      "Recall@AP: 92.61\n",
      "light\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [21:43<00:00,  4.40s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:45<00:00,  5.64s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:13<00:00, 2888.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 90.40\n",
      "Recall@5: 97.35\n",
      "Recall@10: 98.34\n",
      "Recall@top1: 98.44\n",
      "Recall@AP: 91.96\n",
      "wind\n",
      "load model: net_170.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [24:44<00:00,  5.01s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:45<00:00,  5.72s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:13<00:00, 2909.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 89.58\n",
      "Recall@5: 96.65\n",
      "Recall@10: 97.87\n",
      "Recall@top1: 98.00\n",
      "Recall@AP: 91.17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "m = MLPN_()\n",
    "m.batchsize=128\n",
    "\n",
    "from utils.loader import environments \n",
    "\n",
    "for style in environments:\n",
    "    print(style)\n",
    "    m.test(style=style, pth='net_170')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trained on original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [20:27<00:00,  4.15s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.45s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2490.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 93.71\n",
      "Recall@5: 97.87\n",
      "Recall@10: 98.54\n",
      "Recall@top1: 98.60\n",
      "Recall@AP: 94.69\n",
      "dark\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [21:12<00:00,  4.30s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.46s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2453.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 92.21\n",
      "Recall@5: 97.69\n",
      "Recall@10: 98.48\n",
      "Recall@top1: 98.57\n",
      "Recall@AP: 93.45\n",
      "fog\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [27:09<00:00,  5.50s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.42s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:14<00:00, 2543.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 80.77\n",
      "Recall@5: 92.56\n",
      "Recall@10: 95.07\n",
      "Recall@top1: 95.37\n",
      "Recall@AP: 83.45\n",
      "rain\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:41:06<00:00, 20.50s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.43s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2478.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 57.52\n",
      "Recall@5: 74.89\n",
      "Recall@10: 80.74\n",
      "Recall@top1: 81.47\n",
      "Recall@AP: 61.56\n",
      "snow\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:01:52<00:00, 12.54s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.39s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2520.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 40.22\n",
      "Recall@5: 61.06\n",
      "Recall@10: 69.79\n",
      "Recall@top1: 70.82\n",
      "Recall@AP: 45.19\n",
      "fog_rain\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:00:41<00:00, 12.30s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.45s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2391.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 40.30\n",
      "Recall@5: 57.55\n",
      "Recall@10: 65.02\n",
      "Recall@top1: 66.05\n",
      "Recall@AP: 44.51\n",
      "fog_snow\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [44:21<00:00,  8.99s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.42s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2371.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 22.02\n",
      "Recall@5: 36.81\n",
      "Recall@10: 44.76\n",
      "Recall@top1: 45.89\n",
      "Recall@AP: 25.85\n",
      "rain_snow\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [1:26:48<00:00, 17.60s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.44s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2413.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 37.43\n",
      "Recall@5: 56.25\n",
      "Recall@10: 64.51\n",
      "Recall@top1: 65.67\n",
      "Recall@AP: 41.99\n",
      "light\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [21:08<00:00,  4.29s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.44s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2402.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 85.42\n",
      "Recall@5: 95.12\n",
      "Recall@10: 97.03\n",
      "Recall@top1: 97.24\n",
      "Recall@AP: 87.59\n",
      "wind\n",
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [24:52<00:00,  5.04s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:43<00:00,  5.45s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:15<00:00, 2452.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 78.20\n",
      "Recall@5: 91.55\n",
      "Recall@10: 94.54\n",
      "Recall@top1: 94.82\n",
      "Recall@AP: 81.21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for style in environments:\n",
    "    print(style)\n",
    "    m.test(style=style, pth='net_170_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: net_170_.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extract drone feature: 100%|██████████| 296/296 [45:07<00:00,  9.15s/it]\n",
      "Extract satellite feature: 100%|██████████| 8/8 [00:44<00:00,  5.51s/it]\n",
      "Evaluate metrics: 100%|██████████| 37855/37855 [00:14<00:00, 2526.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall@1: 63.14\n",
      "Recall@5: 76.16\n",
      "Recall@10: 80.78\n",
      "Recall@top1: 81.38\n",
      "Recall@AP: 66.21\n"
     ]
    }
   ],
   "source": [
    "m.test(style='mixed', pth='net_170_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
