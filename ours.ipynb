{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ours\n",
    "\n",
    "our code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from shutil import copyfile\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torchvision import models\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.common import setup_seed \n",
    "from utils.loader import environments, init_dataset_train, tensor2label, label2tensor, init_dataset_test\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "\n",
    "class DomainClassifier(nn.Module):\n",
    "    def __init__(self, domin_num=10) -> None:\n",
    "        super(DomainClassifier, self).__init__()\n",
    "        \n",
    "        # adatped from modern backbone, change last fc to adopt domain\n",
    "        self.net = models.resnet18(pretrained=True)\n",
    "        ftr_num = self.net.fc.in_features\n",
    "        self.net.fc = nn.Linear(ftr_num, domin_num)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "    \n",
    "\n",
    "class Ours:\n",
    "    def __init__(self, \n",
    "                 use_wandb=True,\n",
    "                 wandb_key = '16c9a3f92163ef4df08841029e02fded0cd0cfed'\n",
    "                 ) -> None:\n",
    "        self.seed = 2024\n",
    "        self.use_wandb = use_wandb # use wandb to monitor training instead of CLI\n",
    "        self.wandb_key = wandb_key\n",
    "        # init\n",
    "        setup_seed(self.seed)\n",
    "        self.model_dir = os.path.join(os.getcwd(), 'model', 'Ours')\n",
    "        os.environ['TORCH_HOME']='./' \n",
    "        \n",
    "        # \n",
    "        # self.domain_classifer = DomainClassifier() \n",
    "\n",
    "    def train_domain_classifier(self,\n",
    "                name='DomainClassifier',\n",
    "                lr=0.001,\n",
    "                num_epochs=60,\n",
    "                batchsize=16,\n",
    "                h=256,\n",
    "                w=256,\n",
    "                train_num=None,\n",
    "                dataset='University-Release',\n",
    "                checkpoint_interval=20,\n",
    "                checkpoint_start=10,\n",
    "                ):\n",
    "        # load Dataset\n",
    "        image_datasets, dataloaders, dataset_sizes = init_dataset_train(name=dataset, w=w, h=h, style='mixed')\n",
    "\n",
    "        if type(train_num) is int:\n",
    "            indices = list(range(train_num))\n",
    "            s_dataset = Subset(image_datasets['drone'], indices)\n",
    "        else:\n",
    "            s_dataset = image_datasets['drone']\n",
    "        s_dataloader = DataLoader(s_dataset, batch_size=batchsize, shuffle=True, num_workers=0) \n",
    "\n",
    "        # Create Model\n",
    "        model = DomainClassifier()\n",
    "        model = model.cuda()\n",
    "        model.train(True)  # Set model to training mode\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        # trivial settings\n",
    "        # use wandb to log\n",
    "        if self.use_wandb:\n",
    "            import wandb\n",
    "            os.environ[\"WANDB_API_KEY\"] = self.wandb_key\n",
    "            wandb.init(project=\"ACMMMW24\", name=name)\n",
    "        # save pth\n",
    "        if not os.path.isdir(self.model_dir):\n",
    "            os.mkdir(self.model_dir)\n",
    "\n",
    "        \n",
    "        for epoch in range(1, num_epochs+1):     \n",
    "            correct = 0 \n",
    "            total = 0\n",
    "            epoch_loss = 0\n",
    "            for data in tqdm(s_dataloader, ):                                \n",
    "                # get the inputs\n",
    "                inputs, labels, weather = data\n",
    "                now_batch_size,c,h,w = inputs.shape\n",
    "                if now_batch_size<batchsize: # skip the last batch\n",
    "                    continue\n",
    "                wt = label2tensor(weather)\n",
    "                if torch.cuda.is_available():\n",
    "                    inputs = inputs.cuda().detach()\n",
    "                    labels = labels.cuda().detach()\n",
    "                    wt = wt.cuda().detach()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                wo = model(inputs)\n",
    "                loss = criterion(wo, wt)\n",
    "                sssss = tensor2label(wt)\n",
    "                xxxxx = tensor2label(wo)\n",
    "\n",
    "                for i in range(batchsize):\n",
    "                    if sssss[i] == xxxxx[i]:\n",
    "                        correct = correct + 1\n",
    "                total = total + batchsize\n",
    "                epoch_loss += float(loss.cpu().detach().numpy())\n",
    "                loss.backward()\n",
    "                optimizer.step() \n",
    "            if self.use_wandb:\n",
    "                wandb.log({'Loss': epoch_loss, 'Acc': correct/total})\n",
    "            print(\"Epoch: {} Loss: {:.4f} Acc: {:.4f}\".format(epoch, epoch_loss, correct/total))\n",
    "\n",
    "            if epoch % checkpoint_interval == 0 and epoch > checkpoint_start:     \n",
    "                save_filename = '{}_{:03d}.pth'.format(name, epoch)\n",
    "                save_path = os.path.join(os.path.join(os.getcwd(), \"model\", name, save_filename))\n",
    "                torch.save(model.cpu().state_dict(), save_path)\n",
    "                model.cuda() # essential!\n",
    "\n",
    "    def test_domain_classifier_single_batch(self,\n",
    "                                      dataset='University-Release',\n",
    "                                      h=256,\n",
    "                                      w=256,\n",
    "                                      batchsize=8,\n",
    "                                      model_file='DomainClassifier_060.pth'\n",
    "                                      ):\n",
    "        # load Dataset\n",
    "        image_datasets, dataloaders, dataset_sizes = init_dataset_test(name=dataset, w=w, h=h, style='mixed', batchsize=batchsize)\n",
    "        dataiter = iter(dataloaders['query_drone'])\n",
    "        img, label, weather = dataiter.next()\n",
    "        #print(img.shape)\n",
    "        # print(label)\n",
    "        \n",
    "        domain_classifier = DomainClassifier()\n",
    "        domain_classifier.load_state_dict(torch.load(os.path.join(self.model_dir, model_file))) \n",
    "        logits = domain_classifier(img) \n",
    "        pred = torch.softmax(logits, dim=1)\n",
    "\n",
    "        print(logits[0])\n",
    "        print(pred[0])\n",
    "\n",
    "\n",
    "        print(\"GT:        \", weather)\n",
    "        print(\"predicted: \", tensor2label(logits))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Ours(use_wandb=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lyq\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lyq\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-16.9710, -52.0030, -30.8086, -35.0373, -18.2553, -50.1074, -20.0993,\n",
      "        -28.2631,   5.9438, -30.4980], grad_fn=<SelectBackward0>)\n",
      "tensor([1.1174e-10, 6.8235e-26, 1.0929e-16, 1.5927e-18, 3.0935e-11, 4.5423e-25,\n",
      "        4.8933e-12, 1.3936e-15, 1.0000e+00, 1.4911e-16],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "GT:         ('light', 'normal', 'normal', 'snow', 'rain_snow', 'wind', 'dark', 'rain')\n",
      "predicted:  ['light', 'normal', 'normal', 'snow', 'rain_snow', 'wind', 'dark', 'rain']\n"
     ]
    }
   ],
   "source": [
    "# a.train_domain_classifier(num_epochs=3,checkpoint_interval=1, checkpoint_start=0)\n",
    "a.test_domain_classifier_single_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "conda activate pytorch\n",
    "wandb sync d:\\acmmm24-ours\\wandb\\run-20240618_124948-u09o94cy\n",
    "16c9a3f92163ef4df08841029e02fded0cd0cfed\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import torch.utils.data as Data\n",
    "from LPN.image_folder import *\n",
    "\n",
    "environments = {'normal': iaa.Sequential([iaa.Noop()]),\n",
    "                'dark' : iaa.Sequential([\n",
    "                                        # iaa.BlendAlpha(0.5, foreground=iaa.Add(100), background=iaa.Multiply(0.2), seed=31),\n",
    "                                        iaa.MultiplyAndAddToBrightness(mul=0.4, add=-15, seed=1991)]),\n",
    "                'fog'  : iaa.Sequential([iaa.CloudLayer(intensity_mean=225, intensity_freq_exponent=-2, intensity_coarse_scale=2, alpha_min=1.0,\n",
    "                                        alpha_multiplier=0.9, alpha_size_px_max=10, alpha_freq_exponent=-2, sparsity=0.9, density_multiplier=0.5, seed=35)]),\n",
    "                'rain' : iaa.Sequential([iaa.Rain(drop_size=(0.05, 0.1), speed=(0.04, 0.06), seed=38),\n",
    "                                        iaa.Rain(drop_size=(0.05, 0.1), speed=(0.04, 0.06), seed=35),\n",
    "                                        iaa.Rain(drop_size=(0.1, 0.2), speed=(0.04, 0.06), seed=73),\n",
    "                                        iaa.Rain(drop_size=(0.1, 0.2), speed=(0.04, 0.06), seed=93),\n",
    "                                        iaa.Rain(drop_size=(0.05, 0.2), speed=(0.04, 0.06), seed=95)]),\n",
    "                'snow' : iaa.Sequential([iaa.Snowflakes(flake_size=(0.5, 0.8), speed=(0.007, 0.03), seed=38),\n",
    "                                        iaa.Snowflakes(flake_size=(0.5, 0.8), speed=(0.007, 0.03), seed=35),\n",
    "                                        iaa.Snowflakes(flake_size=(0.6, 0.9), speed=(0.007, 0.03), seed=74),\n",
    "                                        iaa.Snowflakes(flake_size=(0.6, 0.9), speed=(0.007, 0.03), seed=94),\n",
    "                                        iaa.Snowflakes(flake_size=(0.5, 0.9), speed=(0.007, 0.03), seed=96)]),\n",
    "                'fog_rain' : iaa.Sequential([iaa.CloudLayer(intensity_mean=225, intensity_freq_exponent=-2, intensity_coarse_scale=2, alpha_min=1.0,\n",
    "                                            alpha_multiplier=0.9, alpha_size_px_max=10, alpha_freq_exponent=-2, sparsity=0.9, density_multiplier=0.5, seed=35),\n",
    "                                            iaa.Rain(drop_size=(0.05, 0.2), speed=(0.04, 0.06), seed=35),\n",
    "                                            iaa.Rain(drop_size=(0.05, 0.2), speed=(0.04, 0.06), seed=36)]),\n",
    "                'fog_snow' : iaa.Sequential([iaa.CloudLayer(intensity_mean=225, intensity_freq_exponent=-2, intensity_coarse_scale=2, alpha_min=1.0,\n",
    "                                            alpha_multiplier=0.9, alpha_size_px_max=10, alpha_freq_exponent=-2, sparsity=0.9, density_multiplier=0.5, seed=35),\n",
    "                                            iaa.Snowflakes(flake_size=(0.5, 0.9), speed=(0.007, 0.03), seed=35),\n",
    "                                            iaa.Snowflakes(flake_size=(0.5, 0.9), speed=(0.007, 0.03), seed=36)]),\n",
    "                'rain_snow' : iaa.Sequential([iaa.Snowflakes(flake_size=(0.5, 0.8), speed=(0.007, 0.03), seed=35),\n",
    "                                            iaa.Rain(drop_size=(0.05, 0.1), speed=(0.04, 0.06), seed=35),\n",
    "                                            iaa.Rain(drop_size=(0.1, 0.2), speed=(0.04, 0.06), seed=92),\n",
    "                                            iaa.Rain(drop_size=(0.05, 0.2), speed=(0.04, 0.06), seed=91),\n",
    "                                            iaa.Snowflakes(flake_size=(0.6, 0.9), speed=(0.007, 0.03), seed=74)]),\n",
    "                'light': iaa.Sequential([iaa.MultiplyAndAddToBrightness(mul=1.6, add=(0, 30), seed=1992)]),\n",
    "                'wind' : iaa.Sequential([iaa.MotionBlur(15, seed=17)])\n",
    "                }\n",
    "\n",
    "environments2index = {env: idx for idx, env in enumerate(environments)}\n",
    "index2environments = [i for i in environments]\n",
    "\n",
    "class WeatherTransform:\n",
    "    def __init__(self, aug='normal') -> None:\n",
    "        self.transform = environments[aug]\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img) # input is PIL\n",
    "        img = self.transform(image=img)\n",
    "        img = Image.fromarray(img)\n",
    "        return img\n",
    "    \n",
    "\n",
    "class MyDataset(datasets.ImageFolder):\n",
    "    # enable various weather enhancement\n",
    "    # use for drone-view only\n",
    "    def __init__(self, root, transform = None, target_transform = None, style='normal', h=384, w=384):\n",
    "        super().__init__(root, transform = transform, target_transform = target_transform)\n",
    "        self.envir_list = [i for i in environments]\n",
    "        self.style_list = self.envir_list + ['mixed']\n",
    "        assert style in self.style_list, f\"style must be one of {self.style_list}\"\n",
    "        self.style = style \n",
    "        # assert stage in ['train', 'test'], f\"style must be one of {['train', 'test']}\"\n",
    "        # self.stage = stage\n",
    "         \n",
    "        # transform setting\n",
    "        self.h = h \n",
    "        self.w = w\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super().__getitem__(index)\n",
    "        # enhance image according to self.style \n",
    "        h = self.h \n",
    "        w = self.w \n",
    "\n",
    "        if self.style=='mixed':\n",
    "            weather = np.random.choice(self.envir_list)\n",
    "        else:\n",
    "            weather = self.style\n",
    "\n",
    "\n",
    "        t = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((h, w), interpolation=InterpolationMode.BICUBIC),\n",
    "                WeatherTransform(aug=weather),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        img = t(img)\n",
    "        return img, target, weather    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "def label2tensor(label, num_classes=10):\n",
    "    idxs = [environments2index[i] for i in label]\n",
    "    idxs = torch.tensor(idxs) \n",
    "    t = torch.nn.functional.one_hot(idxs, num_classes=num_classes).float()\n",
    "    return t\n",
    "\n",
    "def tensor2label(t):\n",
    "    indices = torch.argmax(t, dim=1)\n",
    "    return [index2environments[i] for i in indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test custom dataset(skip freely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = MyDataset(os.path.join(os.getcwd(), 'University-Release', 'train', 'drone'), style='mixed')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img * torch.tensor([0.229, 0.224, 0.225]).view(3,1,1) + torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
    "    img = img.numpy()\n",
    "    plt.imshow(np.transpose(img, (1,2,0)))\n",
    "    plt.show() \n",
    "\n",
    "d = torch.utils.data.DataLoader(a, batch_size=8, shuffle=True, num_workers=0, pin_memory=False)\n",
    "dataiter = iter(d)\n",
    "img, label, weather = dataiter.next()\n",
    "#print(img.shape)\n",
    "print(label)\n",
    "\n",
    "print(weather)\n",
    "x = label2tensor(weather)\n",
    "xx = tensor2label(x)\n",
    "print(xx)\n",
    "\n",
    "\n",
    "\n",
    "imshow(img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build a CNN network to classify weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "class WeatherCNN(nn.Module):\n",
    "    def __init__(self, class_num=10, h=384, w=384, latent_dim=1000):\n",
    "        super(WeatherCNN, self).__init__()\n",
    "        self.w = w \n",
    "        self.h = h\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        fc_input_size = self.get_fc_input_size() # to dynamically calculate fc input size, since h,w changes\n",
    "        self.fc1 = nn.Linear(fc_input_size, latent_dim)\n",
    "        self.fc2 = nn.Linear(latent_dim, class_num)\n",
    "        self.softmax = nn.Softmax(dim=-1)      \n",
    "\n",
    "    def forward(self, xx):\n",
    "        x = self.layer1(xx)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def get_fc_input_size(self):\n",
    "        dummy_imput = torch.zeros(1, 3, self.h, self.w)\n",
    "        x = self.layer1(dummy_imput)\n",
    "        x = self.layer2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return x.shape[1]\n",
    "    \n",
    "def pretrain_WeatherCNN(\n",
    "                name='WeatherCNN',\n",
    "                lr=0.001,\n",
    "                num_epochs=60,\n",
    "                batchsize=16,\n",
    "                h=256,\n",
    "                w=256,\n",
    "                train_num=None,\n",
    "                dataset='University-Release', \n",
    "                style='mixed'):\n",
    "    # load Dataset\n",
    "    image_datasets, dataloaders, dataset_sizes = init_dataset_train(name=dataset, w=w, h=h, style=style)\n",
    "\n",
    "    if type(train_num) is int:\n",
    "        indices = list(range(train_num))\n",
    "        s_dataset = Subset(image_datasets['drone'], indices)\n",
    "    else:\n",
    "        s_dataset = image_datasets['drone']\n",
    "    s_dataloader = DataLoader(s_dataset, batch_size=batchsize, shuffle=True, num_workers=0) \n",
    "\n",
    "    # Create Model\n",
    "    model = WeatherCNN(h=h, w=w)\n",
    "    model = model.cuda()\n",
    "    model.train(True)  # Set model to training mode\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "     \n",
    "    for epoch in range(1, num_epochs+1):     \n",
    "        correct = 0 \n",
    "        total = 0\n",
    "        epoch_loss = 0\n",
    "        for data in s_dataloader:                                \n",
    "            # get the inputs\n",
    "            inputs, labels, weather = data\n",
    "            now_batch_size,c,h,w = inputs.shape\n",
    "            if now_batch_size<batchsize: # skip the last batch\n",
    "                continue\n",
    "            wt = label2tensor(weather)\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda().detach()\n",
    "                labels = labels.cuda().detach()\n",
    "                wt = wt.cuda().detach()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            wo = model(inputs)\n",
    "            loss = criterion(wo, wt)\n",
    "            sssss = tensor2label(wt)\n",
    "            xxxxx = tensor2label(wo)\n",
    "\n",
    "            for i in range(batchsize):\n",
    "                if sssss[i] == xxxxx[i]:\n",
    "                    correct = correct + 1\n",
    "            total = total + batchsize\n",
    "            epoch_loss += float(loss.cpu().detach().numpy())\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "        print(\"Epoch: {} Loss: {:.4f} Acc: {:.4f}\".format(epoch, epoch_loss, correct/total))\n",
    "\n",
    "    # save pth\n",
    "    if not os.path.isdir(os.path.join(os.getcwd(), \"model\", name)):\n",
    "        os.mkdir(os.path.join(os.getcwd(), \"model\", name))\n",
    "    save_filename = 'net_{:03d}_{}x{}.pth'.format(epoch, w, h)\n",
    "    save_path = os.path.join(os.path.join(os.getcwd(), \"model\", name, save_filename))\n",
    "    torch.save(model.cpu().state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 4.6343 Acc: 0.1562\n",
      "Epoch: 2 Loss: 4.6098 Acc: 0.1562\n",
      "Epoch: 3 Loss: 4.9223 Acc: 0.0000\n",
      "Epoch: 4 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 5 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 6 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 7 Loss: 4.4223 Acc: 0.2500\n",
      "Epoch: 8 Loss: 4.4223 Acc: 0.2500\n",
      "Epoch: 9 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 10 Loss: 4.8598 Acc: 0.0312\n",
      "Epoch: 11 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 12 Loss: 4.8598 Acc: 0.0312\n",
      "Epoch: 13 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 14 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 15 Loss: 4.6098 Acc: 0.1562\n",
      "Epoch: 16 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 17 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 18 Loss: 4.8598 Acc: 0.0312\n",
      "Epoch: 19 Loss: 4.9223 Acc: 0.0000\n",
      "Epoch: 20 Loss: 4.6098 Acc: 0.1562\n",
      "Epoch: 21 Loss: 4.6098 Acc: 0.1562\n",
      "Epoch: 22 Loss: 4.8598 Acc: 0.0312\n",
      "Epoch: 23 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 24 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 25 Loss: 4.8598 Acc: 0.0312\n",
      "Epoch: 26 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 27 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 28 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 29 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 30 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 31 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 32 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 33 Loss: 4.4848 Acc: 0.2188\n",
      "Epoch: 34 Loss: 4.9223 Acc: 0.0000\n",
      "Epoch: 35 Loss: 4.5473 Acc: 0.1875\n",
      "Epoch: 36 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 37 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 38 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 39 Loss: 4.9223 Acc: 0.0000\n",
      "Epoch: 40 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 41 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 42 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 43 Loss: 4.8598 Acc: 0.0312\n",
      "Epoch: 44 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 45 Loss: 4.5473 Acc: 0.1875\n",
      "Epoch: 46 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 47 Loss: 4.6098 Acc: 0.1562\n",
      "Epoch: 48 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 49 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 50 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 51 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 52 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 53 Loss: 4.7973 Acc: 0.0625\n",
      "Epoch: 54 Loss: 4.9223 Acc: 0.0000\n",
      "Epoch: 55 Loss: 4.6723 Acc: 0.1250\n",
      "Epoch: 56 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 57 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 58 Loss: 4.8598 Acc: 0.0312\n",
      "Epoch: 59 Loss: 4.7348 Acc: 0.0938\n",
      "Epoch: 60 Loss: 4.6723 Acc: 0.1250\n"
     ]
    }
   ],
   "source": [
    "pretrain_WeatherCNN(train_num=32, w=256, h=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
